---
layout: page
title: Ph.D. thesis
---

<h3>Introduction</h3>
<p>The Fourth Industrial Revolution (Industry 4.0) is a technology-driven revolution that seeks to transform processes,
    systems, and methods through the digitalization and interconnectivity of all assets. Smart Factories, an essential
    pillar of Industry 4.0, require the integration of multiple technologies that lead to an interoperable
    manufacturing plant where almost all components of the value network are connected, coordinated, and share data.
    Artificial Intelligence (AI) has become one of the main vectors for this revoulolution, but one obstacle to its use
    in industry is that algorithms are highly "data consuming."
</p>
<p>
    Unlike other machine learning approaches that rely in a model gorund-truth dataset, Reinforcement Learning (RL) and
    Deep Reinforcement Learning (DRL) algorithms learn thanks to the experience gathered from the interaction of an
    agent with its environment. Although most of the industry processes depend on classic control algorithms that
    exploits the knowledge of the operation dynamics, we argue that RL and DRL approaches can address the same problems,
    and more complex ones that are currently unsolved, introducing generalization capabilities, scalability and
    flexibility into the current industrial environment constraints. However, the major constraint of the application of
    RL to industry problems is the amount of experience an agent consumes until it learns.
</p>
<p>
    This <b>sample efficiency</b> issue of RL algorithms can be addressed relying on the use of virtual environments to
    train the agents. The ideal case would rely on a simulator that is an exact reproduction of the physical setup, but
    in most cases, there will be divergences between both layouts. These divergences can make agents not perform as
    expected when they are deployed in the real environment. To deal with this problem, several <b>transfer learning
        techniques</b> have been developed to bridge the gap between the real world and simulation, known as
    <b>sim-to-real</b>.
</p>
<p>
    Therefore, with this approach the sample efficiency problem is mitigated, but another one raises: <u>the need to
        efficiently transfer the synthetic experience into the real world</u>. Within this framework, my Ph.D. thesis is
    framed as <b>the search for an optimized pipeline to solve the sim-to-real problem</b>.
</p>
<p>
<div class="image"><img src="images/pic_Thesis_1.jpeg" alt="" height="300" /></div>
</p>
<hr />
<h3>Ph.D. Thesis objectives and contributions</h3>
<p>According to state-of-the-art transfer learning techniques, we argue that there is not a single technique that might
    tackle properly the problem, so the optimal sim-to-real solution should be an approach that integrates various
    methods to boost their strengths and compensate their weaknesses.
</p>
<p>
    Hence the Ph.D. Thesis objectives and contributions might be sum-up as follows:
<h5>Objectives</h5>
<ol>
    <li>Design an optimized pipeline for the transferring experience process between (deep) reinforcement learning
        agents.</li>
    <li>Validate the optimized pipeline and its generalization capabilities.</li>
    <li>Define the methodology that needs to be followed to implement the optimized pipeline in a completely different
        industrial application.</li>
</ol>
<h5>Contributions</h5>
<ul>
    <li>Based on a detailed analysis of the transfer learning techniques, select the most suitable and
        interesting procedures that might be implemented in an industrial application.</li>
    <li>Use Domain Randomization to speed up the transfer of knowledge process and quantify the benefit of adding
        diversity in a sim-to-sim approach.</li>
    <li>An optimized pipeline that efficiently bridges the reality gap and is appropriate for industrial use cases.</li>
    <li>Validation of the proposed tool with two different robots and a descriptive methodology that should be followed
        to implement it in another industrial process (in this case, a general process that does not need to be a
        robot).</li>
    <li>Analysis of the drivers that interfere with and hinder transferring experience among simulated and real assets.
    </li>
</ul>
</p>
<hr />
<h3>Ph.D. Thesis case study and assets</h3>
<h5>Case study</h5>
<p> The selected industrial operation is Pick & Place, the task where robotic arms pick a component and place it
    anywhere else. It was selected because: 1) currently, it is a problem that is not solved for chaotic environments;
    2) it is a cross-cutting process in many industries; and 3) we can access to the assets that comprise the challenge,
    i.e. two different robotic arms. </p>
<p>
    We are first focusing on the algorithm that learns how to approach the arm to a target that is positioned randomly
    within the robot workspace area. The robotic arm starts with a random initial pose. This framework corresponds to
    the first part of a Pick & Place process.
    The input to the agent is just the environment image from which it must infer the robot and the target pose. Since
    the input is a picture, the representation learning process is embedded in the model due to the state's high
    dimensionality.
</p>
<h5>Assets</h5>
<p>We have chosen two different robotic arms, an industrial robot, the <a target="_blank"
        href="https://new.abb.com/products/robotics/robots/articulated-robots/irb-120">IRB120
        by ABB</a> and a collaborative one, the <a target="_blank"
        href="https://www.universal-robots.com/products/ur3-robot/">UR3e by Universal Robots</a>. Both of these models
    have 6 degrees of freedom, but they differ significantly in terms of their morphology. We believe that these
    differences will enable us to test our proposal under two distinct environments, while still allowing the agent to
    perform the same task. This will enable us to evaluate the performance of our solution in real-world scenarios and
    develop a solution that is scalable and applicable in various industry problems.
</p>
<div class="row">
    <div class="6u 12u$(medium)">
        <div class="image"><img src="images/pic_IRB120Env.JPEG" alt="" height="300" /></div>
    </div>
    <div class="6u 12u$(medium)">
        <div class="image"><img src="images/pic_UR3eEnv.JPEG" alt="" height="300" /></div>
    </div>
</div>
<hr />
<h3>From idea to reality: Milestones achieved so far</h3>
<p>According to state-of-the-art transfer learning techniques, we argue that there is not a single technique that might
    tackle properly the problem, so the optimal sim-to-real solution should be an approach that integrates various
    methods to boost their strengths and compensate their weaknesses. Particularly, we have been exploring the
    intersection between Progressive Neural Networks (PNNs) and Domain Randomization (DR), although we plan to add
    Domain Adaptation (DA) to the equation and some object-centric concepts. The ultimate goal is to achieve a procedure
    that endows resulting models with optimized generalization properties, seeking to avoid the dependency on
    photorealistic simulators which might increase the computational resources needed, and the use of complex algorithms
    that might result in task or environment overfitting.
</p>